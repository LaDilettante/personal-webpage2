<p>Reference: Imbens &amp; Wooldrige (2009). Recent developments in the econometrics of program evaluation.<a href="http://dash.harvard.edu/bitstream/handle/1/3043416/imbens_recent.pdf?sequence=2">Open-access link</a></p>

<h2 id="section-53-using-regression-method-to-estimate-average-treatment-effect">Section 5.3: Using regression method to estimate average treatment effect.</h2>

<blockquote>
  <p>To describe the general approach to regression methods for estimating average treatment effects, define <script type="math/tex">\mu_0(x)</script> and <script type="math/tex">\mu_1(x)</script> to be the two regression functions for the potential outcomes.
<script type="math/tex">\mu_0(x) = E[Y_i(0) \vert X_i=x] = E[Y_i(0) \vert W_i=0, X_i=x] = \alpha_0 + \beta_0 ' (x - \psi_X)</script>
<script type="math/tex">\mu_1(x) = E[Y_i(1) \vert X_i=x] = E[Y_i(1) \vert W_i=1, X_i=x] =\alpha_1 + \beta_1 ' (x - \psi_X)</script></p>
</blockquote>

<p><strong>Comment:</strong> The first equality is the definition. The second equality is true due to unconfoundedness. The third equality is because we’re assuming the simplest case in which the conditional mean is linear in the parameters.</p>

<p>Note that <script type="math/tex">x, \psi_X</script> refer to the covariates of the entire population, not just of the treated or untreated. This is because <script type="math/tex">\mu_0, \mu_1</script> refer to the two potential outcomes, and all observations have both potential outcomes.</p>

<p>In other words, for each observation <script type="math/tex">i</script>, we can plug in <script type="math/tex">i</script>’s covariates <script type="math/tex">x</script> into <script type="math/tex">\mu_0(x)</script> and <script type="math/tex">\mu_1(x)</script> in order to get the untreated and treated potential outcomes for observation <script type="math/tex">i</script>.</p>

<blockquote>
  <p>Then <script type="math/tex">\hat\tau_{reg}</script> is simply
<script type="math/tex">\hat\tau_{reg} = \hat{\alpha}_1 - \hat{\alpha}_0 \qquad (13)</script></p>
</blockquote>

<p><strong>Comment</strong>: The authors skip some steps here, which I’ll elaborate as follows.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\tau_{reg} &= E[Y_i(1) - Y_i(0)] & \text{The average treatment effect} \\
&= E[E[Y_i(1) - Y_i(0) \vert X_i=x]] & \text{Law of Iterated Expectation} \\
&= E[E[Y_i(1) \vert X_i=x] - E[Y_i(0) \vert X_i=x]] \\
&= E[E[Y_i(1) \vert W_i=1, X_i=x] - E[Y_i(0) \vert W_i=0,X_i=x]] & \text{Due to unconfoundedness, as explained on p 23} \\
&= E[\mu_1(x) - \mu_0(x)] 
\end{align} %]]></script>

<p>Notice that we can’t estimate <script type="math/tex">E[Y_i(1) \vert X_i=x]</script> since <script type="math/tex">Y_i(1)</script> is not available for the untreated <script type="math/tex">i</script>’s. However, <script type="math/tex">E[Y_i(1) \vert W_i=1, X_i=x]</script> <em>can</em> be estimated, so <script type="math/tex">\hat\mu_1(x)</script> exists. In order to estimate <script type="math/tex">\hat\mu_0(x), \hat\mu_1(x)</script>, we give them a parametric model like the authors do (p. 24):</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\mu_0(x) &= \alpha_0 + \beta_0 ' (x - \psi_X) \\
\mu_1(x) &= \alpha_1 + \beta_1 ' (x - \psi_X)
\end{align} %]]></script>

<p>and just replacing all the parameters with its estimates (we’ll talk about what these estimates actually are):</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\hat\mu_0(x) &= \hat\alpha_0 + \hat\beta_0 ' (x - \bar X) \\
\hat\mu_1(x) &= \hat\alpha_1 + \hat\beta_1 ' (x - \bar X)
\end{align} %]]></script>

<p>But what is <script type="math/tex">\hat\mu_0(x)</script>? Recall that <script type="math/tex">\mu_0(x) = E[Y_i(0) \vert W_i=0, X_i=x]</script>. Since we observe <script type="math/tex">Y_i(0)</script> for all the untreated observations, <script type="math/tex">\hat\mu_0(x_i)</script> is simply <script type="math/tex">Y_i</script>!</p>

<p>To derive Eq. 13, just plug in the formula for <script type="math/tex">\hat\mu_0(x), \hat\mu_1(x)</script>.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\hat\tau_{reg} &= \frac{1}{N} \sum_{i=1}^{N} \left( \hat\mu_1(X_i) - \hat\mu_0(X_i) \right) \\
&= \frac{1}{N} \sum_{i=1}^{N} \left( \hat\alpha_1 + \hat\beta_1 ' (x - \bar X) - \hat\alpha_0 - \hat\beta_0 ' (x - \bar X) \right) \\
&= \hat\alpha_1 - \hat\alpha_0 + \hat\beta_1' \frac{1}{N} \sum_{i=1}^{N} (x - \bar X) - \hat\beta_0 ' \frac{1}{N} \sum_{i=1}^{N} (x - \bar X) \\
&= \hat\alpha_1 - \hat\alpha_0 + 0 + 0 \\
&= \hat\alpha_1 - \hat\alpha_0 & \text{Arrived at their Eq. 13}
\end{align} %]]></script>

<blockquote>
  <p>A different representation of <script type="math/tex">\hat\tau_{reg}</script> is useful in order to illustrate some of the concerns with regression estimators in this setting. Suppose we do use the linear model in (12). It can be shown that</p>

  <script type="math/tex; mode=display">\hat\tau_{reg} = \bar Y_1 - \bar Y_0 - \left( \frac{N_0}{N_0 + N_1} \hat\beta_1 + \frac{N_1}{N_0 + N_1} \hat\beta_0 \right)' (\bar X_1 - \bar X_0) \qquad (14)</script>
</blockquote>

<p><strong>Comment</strong>: To derive Eq. 14, we have to substitute out <script type="math/tex">\hat\alpha_0, \hat\alpha_1</script> with the other terms. Notice that:</p>

<script type="math/tex; mode=display">\hat\alpha_0 = \hat\mu_0(x) - \hat\beta_0'(x - \bar X)</script>

<p>But what is <script type="math/tex">\hat\mu_0(x)</script>? Recall that <script type="math/tex">\mu_0(x) = E[Y_i(0) \vert W_i=0, X_i=x]</script>. Since we observe <script type="math/tex">Y_i(0)</script> for all the untreated observations, <script type="math/tex">\hat\mu_0(x_i)</script> is simply <script type="math/tex">Y_i</script>!</p>

<p>Therefore,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\hat\mu_0(x) &= \hat\alpha_0 + \hat\beta_0 ' (x - \bar X) \\
\frac{1}{N_0} \sum_{i=1}^{N_0} \hat\mu_0(x_i) &= \hat\alpha_0 + \hat\beta_0 ' \frac{1}{N_0} \sum_{i=1}^{N_0} (x_i - \bar X) & \text{summing over untreated units}\\
\frac{1}{N_0} \sum_{i=1}^{N_0} Y_i &= \hat\alpha_0 + \hat\beta_0 ' \frac{1}{N_0} \sum_{i=1}^{N_0} (x_i - \bar X) & \text{Using the fact above, i.e.} \hat\mu_0(x_i) = Y_i\\
\bar Y_0 &= \hat\alpha_0 + \hat\beta_0 '(\bar X_0 - \bar X) \\
\hat\alpha_0 &= \bar Y_0 - \hat\beta_0 '(\bar X_0 - \bar X)
\end{align} %]]></script>

<p>We plug the above formula for <script type="math/tex">\hat\alpha_0, \hat\alpha_1</script> into <script type="math/tex">\hat\tau_{reg}</script> and do some transformation to get Eq. 14. Specifically,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\hat\alpha_0 &= \bar Y_0 - \hat\beta_0 '(\bar X_0 - \bar X) \\
&= \bar Y_0 - \hat\beta_0 '(\bar X_0 - \frac{\bar X_0 N_0 + \bar X_1 N_1}{N_0 + N_1}) \\
&= \bar Y_0 - \hat\beta_0 ' \frac{N_1}{N_0+N_1} \left( \bar X_0 \frac{N_0 + N_1}{N_1} - \bar X_0 \frac{N_0}{N_1} - \bar X_1 \right) \\
&= \bar Y_0 - \hat\beta_0 ' \frac{N_1}{N_0+N_1} (\bar X_0 - \bar X_1) \\
\hat\alpha_1 &= \bar Y_1 - \hat\beta_1 ' \frac{N_0}{N_0+N_1} (\bar X_1 - \bar X_0) & \text{similar to above}
\end{align} %]]></script>

<p>Plugging <script type="math/tex">\hat\alpha_0, \hat\alpha_1</script> into <script type="math/tex">\hat\tau_{reg}</script>, we now have Eq. 14</p>
